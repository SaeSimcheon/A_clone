{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qB507Q1OWCZB"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 uninstall --yes torch\n",
        "!pip3 install torch==1.15.0\n",
        "!pip3 install torchtext==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1R3AyblXVQv",
        "outputId": "3165487a-92b2-41ed-8add-33766b3a9c56"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.6.0+cu124\n",
            "Uninstalling torch-2.6.0+cu124:\n",
            "  Successfully uninstalled torch-2.6.0+cu124\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.15.0 (from versions: 1.13.0, 1.13.1, 2.0.0, 2.0.1, 2.1.0, 2.1.1, 2.1.2, 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.15.0\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.6.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.6.0) (2.32.3)\n",
            "Collecting torch (from torchtext==0.6.0)\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.6.0) (1.26.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from torchtext==0.6.0) (1.17.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from torchtext==0.6.0) (0.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.6.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.6.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.6.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.6.0) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchtext==0.6.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchtext==0.6.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchtext==0.6.0) (3.0.2)\n",
            "Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchtext\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torch-2.6.0 torchtext-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "import torch\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from collections import Counter\n",
        "from torchtext.vocab import Vocab\n",
        "from torchtext.utils import download_from_url, extract_archive\n",
        "import io"
      ],
      "metadata": {
        "id": "QA71hoKBXN8L"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_test = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
        "download_from_url(url_test,root = '/content')\n",
        "\n",
        "from_path = './training.tar.gz'\n",
        "to_path = './'\n",
        "train_filepaths = torchtext.utils.extract_archive(from_path, to_path)\n",
        "\n",
        "url_test = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
        "download_from_url(url_test,'./validation.tar.gz',root = '/content')\n",
        "\n",
        "from_path = './validation.tar.gz'\n",
        "to_path = './'\n",
        "val_filepaths = torchtext.utils.extract_archive(from_path, to_path)\n",
        "\n",
        "#url_test = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/test.tar.gz\"\n",
        "#download_from_url(url_test,root = '/content')"
      ],
      "metadata": {
        "id": "rRfBoSy2WKfe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS5UZV-4YPT2",
        "outputId": "fa2616ab-0d48-4b47-e6ac-662b83d4ad2c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from de-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aYvpp-MiWCZF"
      },
      "outputs": [],
      "source": [
        "#train_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]\n",
        "#val_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in val_urls]\n",
        "#test_filepaths = [extract_archive(download_from_url(url_base + url))[0] for url in test_urls]\n",
        "\n",
        "de_tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\n",
        "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "def build_vocab(filepath, tokenizer):\n",
        "  counter = Counter()\n",
        "  with io.open(filepath, encoding=\"utf8\") as f:\n",
        "    for string_ in f:\n",
        "      counter.update(tokenizer(string_))\n",
        "  return Vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n",
        "\n",
        "de_vocab = build_vocab(train_filepaths[0], de_tokenizer)\n",
        "en_vocab = build_vocab(train_filepaths[1], en_tokenizer)\n",
        "\n",
        "def data_process(filepaths):\n",
        "  raw_de_iter = iter(io.open(filepaths[0], encoding=\"utf8\"))\n",
        "  raw_en_iter = iter(io.open(filepaths[1], encoding=\"utf8\"))\n",
        "  data = []\n",
        "  for (raw_de, raw_en) in zip(raw_de_iter, raw_en_iter):\n",
        "    de_tensor_ = torch.tensor([de_vocab[token] for token in de_tokenizer(raw_de)],\n",
        "                            dtype=torch.long)\n",
        "    en_tensor_ = torch.tensor([en_vocab[token] for token in en_tokenizer(raw_en)],\n",
        "                            dtype=torch.long)\n",
        "    data.append((de_tensor_, en_tensor_))\n",
        "  return data\n",
        "\n",
        "train_data = data_process(train_filepaths)\n",
        "val_data = data_process(val_filepaths)\n",
        "#test_data = data_process(test_filepaths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPd61E1RWCZG"
      },
      "source": [
        "``DataLoader``\n",
        "----------------\n",
        "The last ``torch`` specific feature we'll use is the ``DataLoader``,\n",
        "which is easy to use since it takes the data as its\n",
        "first argument. Specifically, as the docs say:\n",
        "``DataLoader`` combines a dataset and a sampler, and provides an iterable over the given dataset. The ``DataLoader`` supports both map-style and iterable-style datasets with single- or multi-process loading, customizing loading order and optional automatic batching (collation) and memory pinning.\n",
        "\n",
        "Please pay attention to ``collate_fn`` (optional) that merges a list of samples to form a mini-batch of Tensor(s). Used when using batched loading from a map-style dataset.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "teXls_NqWCZH",
        "outputId": "b4359b40-bc8b-4a65-a89c-65bd4b9ef556",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BATCH_SIZE 128\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "print('BATCH_SIZE',BATCH_SIZE)\n",
        "PAD_IDX = de_vocab['<pad>']\n",
        "BOS_IDX = de_vocab['<bos>']\n",
        "EOS_IDX = de_vocab['<eos>']\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def generate_batch(data_batch):\n",
        "  de_batch, en_batch = [], []\n",
        "  for (de_item, en_item) in data_batch:\n",
        "    de_batch.append(torch.cat([torch.tensor([BOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0))\n",
        "    en_batch.append(torch.cat([torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0))\n",
        "  de_batch = pad_sequence(de_batch, padding_value=PAD_IDX)\n",
        "  en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n",
        "  return de_batch, en_batch\n",
        "\n",
        "train_iter = DataLoader(train_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=generate_batch)\n",
        "valid_iter = DataLoader(val_data, batch_size=BATCH_SIZE,\n",
        "                        shuffle=True, collate_fn=generate_batch)\n",
        "#test_iter = DataLoader(test_data, batch_size=BATCH_SIZE,\n",
        "#                       shuffle=True, collate_fn=generate_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kpCqcYsWCZH"
      },
      "source": [
        "Defining our ``nn.Module`` and ``Optimizer``\n",
        "----------------\n",
        "That's mostly it from a ``torchtext`` perspecive: with the dataset built\n",
        "and the iterator defined, the rest of this tutorial simply defines our\n",
        "model as an ``nn.Module``, along with an ``Optimizer``, and then trains it.\n",
        "\n",
        "Our model specifically, follows the architecture described\n",
        "`here <https://arxiv.org/abs/1409.0473>`__ (you can find a\n",
        "significantly more commented version\n",
        "`here <https://github.com/SethHWeidman/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb>`__).\n",
        "\n",
        "Note: this model is just an example model that can be used for language\n",
        "translation; we choose it because it is a standard model for the task,\n",
        "not because it is the recommended model to use for translation. As you're\n",
        "likely aware, state-of-the-art models are currently based on Transformers;\n",
        "you can see PyTorch's capabilities for implementing Transformer layers\n",
        "`here <https://pytorch.org/docs/stable/nn.html#transformer-layers>`__; and\n",
        "in particular, the \"attention\" used in the model below is different from\n",
        "the multi-headed self-attention present in a transformer model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-b3oJeRWCZI",
        "outputId": "728b6237-8962-4b85-c100-b24709612d9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 3,491,070 trainable parameters\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from typing import Tuple\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim: int,\n",
        "                 emb_dim: int,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 dropout: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor) -> Tuple[Tensor]:\n",
        "        print('input of Encoder : src.size() in Encoder',src.size())\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "        print('Result of Embedding and dropout : embedded.size() in Encoder',embedded.size())\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "        print('Result of RNN : outputs.size() in Encoder',outputs.size())\n",
        "        print('Result of RNN : hidden.size() in Encoder',hidden.size())\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "        print('Result of concat and affine layer :hidden.size() in Encoder after self.fc',hidden.size())\n",
        "\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 attn_dim: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "\n",
        "        self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n",
        "\n",
        "        self.attn = nn.Linear(self.attn_in, attn_dim)\n",
        "\n",
        "    def forward(self,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((\n",
        "            repeated_decoder_hidden,\n",
        "            encoder_outputs),\n",
        "            dim = 2)))\n",
        "\n",
        "        attention = torch.sum(energy, dim=2)\n",
        "\n",
        "        return F.softmax(attention, dim=1)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 output_dim: int,\n",
        "                 emb_dim: int,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 dropout: int,\n",
        "                 attention: nn.Module):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "\n",
        "        self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def _weighted_encoder_rep(self,\n",
        "                              decoder_hidden: Tensor,\n",
        "                              encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        a = self.attention(decoder_hidden, encoder_outputs)\n",
        "\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
        "\n",
        "        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n",
        "\n",
        "        return weighted_encoder_rep\n",
        "\n",
        "\n",
        "    def forward(self,\n",
        "                input: Tensor,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tuple[Tensor]:\n",
        "\n",
        "        input = input.unsqueeze(0)\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden,\n",
        "                                                          encoder_outputs)\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n",
        "\n",
        "        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
        "\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
        "\n",
        "        output = self.out(torch.cat((output,\n",
        "                                     weighted_encoder_rep,\n",
        "                                     embedded), dim = 1))\n",
        "\n",
        "        return output, decoder_hidden.squeeze(0)\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 encoder: nn.Module,\n",
        "                 decoder: nn.Module,\n",
        "                 device: torch.device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                teacher_forcing_ratio: float = 0.5) -> Tensor:\n",
        "\n",
        "        batch_size = src.shape[1]\n",
        "        max_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        # first input to the decoder is the <sos> token\n",
        "        output = trg[0,:]\n",
        "\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.max(1)[1]\n",
        "            output = (trg[t] if teacher_force else top1)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "INPUT_DIM = len(de_vocab)\n",
        "OUTPUT_DIM = len(en_vocab)\n",
        "# ENC_EMB_DIM = 256\n",
        "# DEC_EMB_DIM = 256\n",
        "# ENC_HID_DIM = 512\n",
        "# DEC_HID_DIM = 512\n",
        "# ATTN_DIM = 64\n",
        "# ENC_DROPOUT = 0.5\n",
        "# DEC_DROPOUT = 0.5\n",
        "\n",
        "ENC_EMB_DIM = 32\n",
        "DEC_EMB_DIM = 32\n",
        "ENC_HID_DIM = 64\n",
        "DEC_HID_DIM = 64\n",
        "ATTN_DIM = 8\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "\n",
        "def init_weights(m: nn.Module):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "def count_parameters(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ODNYWfQWCZJ"
      },
      "source": [
        "Note: when scoring the performance of a language translation model in\n",
        "particular, we have to tell the ``nn.CrossEntropyLoss`` function to\n",
        "ignore the indices where the target is simply padding.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8W2QeeCwWCZK"
      },
      "outputs": [],
      "source": [
        "PAD_IDX = en_vocab.stoi['<pad>']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAMNdlJBWCZK"
      },
      "source": [
        "Finally, we can train and evaluate this model:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P-tBLFAjWCZL",
        "outputId": "98a9d994-d4b3-476e-dfe5-1b3ed3af854b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "src.size() in Encoder torch.Size([33, 128])\n",
            "embedded.size() in Encoder torch.Size([33, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([33, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([25, 128])\n",
            "embedded.size() in Encoder torch.Size([25, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([25, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([37, 128])\n",
            "embedded.size() in Encoder torch.Size([37, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([37, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([27, 128])\n",
            "embedded.size() in Encoder torch.Size([27, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([27, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([31, 128])\n",
            "embedded.size() in Encoder torch.Size([31, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([31, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([30, 128])\n",
            "embedded.size() in Encoder torch.Size([30, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([30, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([38, 128])\n",
            "embedded.size() in Encoder torch.Size([38, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([38, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([28, 128])\n",
            "embedded.size() in Encoder torch.Size([28, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([28, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([31, 128])\n",
            "embedded.size() in Encoder torch.Size([31, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([31, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([35, 128])\n",
            "embedded.size() in Encoder torch.Size([35, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([35, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([32, 128])\n",
            "embedded.size() in Encoder torch.Size([32, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([32, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([31, 128])\n",
            "embedded.size() in Encoder torch.Size([31, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([31, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([31, 128])\n",
            "embedded.size() in Encoder torch.Size([31, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([31, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([34, 128])\n",
            "embedded.size() in Encoder torch.Size([34, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([34, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([30, 128])\n",
            "embedded.size() in Encoder torch.Size([30, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([30, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([36, 128])\n",
            "embedded.size() in Encoder torch.Size([36, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([36, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([31, 128])\n",
            "embedded.size() in Encoder torch.Size([31, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([31, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([28, 128])\n",
            "embedded.size() in Encoder torch.Size([28, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([28, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([34, 128])\n",
            "embedded.size() in Encoder torch.Size([34, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([34, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([31, 128])\n",
            "embedded.size() in Encoder torch.Size([31, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([31, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([28, 128])\n",
            "embedded.size() in Encoder torch.Size([28, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([28, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([28, 128])\n",
            "embedded.size() in Encoder torch.Size([28, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([28, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([32, 128])\n",
            "embedded.size() in Encoder torch.Size([32, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([32, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([37, 128])\n",
            "embedded.size() in Encoder torch.Size([37, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([37, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([26, 128])\n",
            "embedded.size() in Encoder torch.Size([26, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([26, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([37, 128])\n",
            "embedded.size() in Encoder torch.Size([37, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([37, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([32, 128])\n",
            "embedded.size() in Encoder torch.Size([32, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([32, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([34, 128])\n",
            "embedded.size() in Encoder torch.Size([34, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([34, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([32, 128])\n",
            "embedded.size() in Encoder torch.Size([32, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([32, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([33, 128])\n",
            "embedded.size() in Encoder torch.Size([33, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([33, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([27, 128])\n",
            "embedded.size() in Encoder torch.Size([27, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([27, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([32, 128])\n",
            "embedded.size() in Encoder torch.Size([32, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([32, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([37, 128])\n",
            "embedded.size() in Encoder torch.Size([37, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([37, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([28, 128])\n",
            "embedded.size() in Encoder torch.Size([28, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([28, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([30, 128])\n",
            "embedded.size() in Encoder torch.Size([30, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([30, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([34, 128])\n",
            "embedded.size() in Encoder torch.Size([34, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([34, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([39, 128])\n",
            "embedded.size() in Encoder torch.Size([39, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([39, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([34, 128])\n",
            "embedded.size() in Encoder torch.Size([34, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([34, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([33, 128])\n",
            "embedded.size() in Encoder torch.Size([33, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([33, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([30, 128])\n",
            "embedded.size() in Encoder torch.Size([30, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([30, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([32, 128])\n",
            "embedded.size() in Encoder torch.Size([32, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([32, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([27, 128])\n",
            "embedded.size() in Encoder torch.Size([27, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([27, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([25, 128])\n",
            "embedded.size() in Encoder torch.Size([25, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([25, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([34, 128])\n",
            "embedded.size() in Encoder torch.Size([34, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([34, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([32, 128])\n",
            "embedded.size() in Encoder torch.Size([32, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([32, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([25, 128])\n",
            "embedded.size() in Encoder torch.Size([25, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([25, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([28, 128])\n",
            "embedded.size() in Encoder torch.Size([28, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([28, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([37, 128])\n",
            "embedded.size() in Encoder torch.Size([37, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([37, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([34, 128])\n",
            "embedded.size() in Encoder torch.Size([34, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([34, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([38, 128])\n",
            "embedded.size() in Encoder torch.Size([38, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([38, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([26, 128])\n",
            "embedded.size() in Encoder torch.Size([26, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([26, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([28, 128])\n",
            "embedded.size() in Encoder torch.Size([28, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([28, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([36, 128])\n",
            "embedded.size() in Encoder torch.Size([36, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([36, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([26, 128])\n",
            "embedded.size() in Encoder torch.Size([26, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([26, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([28, 128])\n",
            "embedded.size() in Encoder torch.Size([28, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([28, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([37, 128])\n",
            "embedded.size() in Encoder torch.Size([37, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([37, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([35, 128])\n",
            "embedded.size() in Encoder torch.Size([35, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([35, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([30, 128])\n",
            "embedded.size() in Encoder torch.Size([30, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([30, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([46, 128])\n",
            "embedded.size() in Encoder torch.Size([46, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([46, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([33, 128])\n",
            "embedded.size() in Encoder torch.Size([33, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([33, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([33, 128])\n",
            "embedded.size() in Encoder torch.Size([33, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([33, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([31, 128])\n",
            "embedded.size() in Encoder torch.Size([31, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([31, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([27, 128])\n",
            "embedded.size() in Encoder torch.Size([27, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([27, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([27, 128])\n",
            "embedded.size() in Encoder torch.Size([27, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([27, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([28, 128])\n",
            "embedded.size() in Encoder torch.Size([28, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([28, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([30, 128])\n",
            "embedded.size() in Encoder torch.Size([30, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([30, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([27, 128])\n",
            "embedded.size() in Encoder torch.Size([27, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([27, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([35, 128])\n",
            "embedded.size() in Encoder torch.Size([35, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([35, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([33, 128])\n",
            "embedded.size() in Encoder torch.Size([33, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([33, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([27, 128])\n",
            "embedded.size() in Encoder torch.Size([27, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([27, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([25, 128])\n",
            "embedded.size() in Encoder torch.Size([25, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([25, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([31, 128])\n",
            "embedded.size() in Encoder torch.Size([31, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([31, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([24, 128])\n",
            "embedded.size() in Encoder torch.Size([24, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([24, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([31, 128])\n",
            "embedded.size() in Encoder torch.Size([31, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([31, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([27, 128])\n",
            "embedded.size() in Encoder torch.Size([27, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([27, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([30, 128])\n",
            "embedded.size() in Encoder torch.Size([30, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([30, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([30, 128])\n",
            "embedded.size() in Encoder torch.Size([30, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([30, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([30, 128])\n",
            "embedded.size() in Encoder torch.Size([30, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([30, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([42, 128])\n",
            "embedded.size() in Encoder torch.Size([42, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([42, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([34, 128])\n",
            "embedded.size() in Encoder torch.Size([34, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([34, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([27, 128])\n",
            "embedded.size() in Encoder torch.Size([27, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([27, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([27, 128])\n",
            "embedded.size() in Encoder torch.Size([27, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([27, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([25, 128])\n",
            "embedded.size() in Encoder torch.Size([25, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([25, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([47, 128])\n",
            "embedded.size() in Encoder torch.Size([47, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([47, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([33, 128])\n",
            "embedded.size() in Encoder torch.Size([33, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([33, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([31, 128])\n",
            "embedded.size() in Encoder torch.Size([31, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([31, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([29, 128])\n",
            "embedded.size() in Encoder torch.Size([29, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([29, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([31, 128])\n",
            "embedded.size() in Encoder torch.Size([31, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([31, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([26, 128])\n",
            "embedded.size() in Encoder torch.Size([26, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([26, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([30, 128])\n",
            "embedded.size() in Encoder torch.Size([30, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([30, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([31, 128])\n",
            "embedded.size() in Encoder torch.Size([31, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([31, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([35, 128])\n",
            "embedded.size() in Encoder torch.Size([35, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([35, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([38, 128])\n",
            "embedded.size() in Encoder torch.Size([38, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([38, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([35, 128])\n",
            "embedded.size() in Encoder torch.Size([35, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([35, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([34, 128])\n",
            "embedded.size() in Encoder torch.Size([34, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([34, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([30, 128])\n",
            "embedded.size() in Encoder torch.Size([30, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([30, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([33, 128])\n",
            "embedded.size() in Encoder torch.Size([33, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([33, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([26, 128])\n",
            "embedded.size() in Encoder torch.Size([26, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([26, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([25, 128])\n",
            "embedded.size() in Encoder torch.Size([25, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([25, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([35, 128])\n",
            "embedded.size() in Encoder torch.Size([35, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([35, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([33, 128])\n",
            "embedded.size() in Encoder torch.Size([33, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([33, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([32, 128])\n",
            "embedded.size() in Encoder torch.Size([32, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([32, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([30, 128])\n",
            "embedded.size() in Encoder torch.Size([30, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([30, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([27, 128])\n",
            "embedded.size() in Encoder torch.Size([27, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([27, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([28, 128])\n",
            "embedded.size() in Encoder torch.Size([28, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([28, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([33, 128])\n",
            "embedded.size() in Encoder torch.Size([33, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([33, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([26, 128])\n",
            "embedded.size() in Encoder torch.Size([26, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([26, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([31, 128])\n",
            "embedded.size() in Encoder torch.Size([31, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([31, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([32, 128])\n",
            "embedded.size() in Encoder torch.Size([32, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([32, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([28, 128])\n",
            "embedded.size() in Encoder torch.Size([28, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([28, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n",
            "hidden.size() in Encoder after self.fc torch.Size([128, 64])\n",
            "src.size() in Encoder torch.Size([27, 128])\n",
            "embedded.size() in Encoder torch.Size([27, 128, 32])\n",
            "outputs.size() in Encoder torch.Size([27, 128, 128])\n",
            "hidden.size() in Encoder torch.Size([2, 128, 64])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c7d466d02b72>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCLIP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-c7d466d02b72>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-9bfe34475994>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_vocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;31m# first input to the decoder is the <sos> token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-9bfe34475994>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outputs.size() in Encoder'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hidden.size() in Encoder'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hidden.size() in Encoder after self.fc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import math\n",
        "import time\n",
        "\n",
        "\n",
        "def train(model: nn.Module,\n",
        "          iterator: torch.utils.data.DataLoader,\n",
        "          optimizer: optim.Optimizer,\n",
        "          criterion: nn.Module,\n",
        "          clip: float):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for _, (src, trg) in enumerate(iterator):\n",
        "        src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model: nn.Module,\n",
        "             iterator: torch.utils.data.DataLoader,\n",
        "             criterion: nn.Module):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, (src, trg) in enumerate(iterator):\n",
        "            src, trg = src.to(device), trg.to(device)\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def epoch_time(start_time: int,\n",
        "               end_time: int):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iter, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "test_loss = evaluate(model, test_iter, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u99wx7wJWCZM"
      },
      "source": [
        "Next steps\n",
        "--------------\n",
        "\n",
        "- Check out the rest of Ben Trevett's tutorials using ``torchtext``\n",
        "  `here <https://github.com/bentrevett/>`__\n",
        "- Stay tuned for a tutorial using other ``torchtext`` features along\n",
        "  with ``nn.Transformer`` for language modeling via next word prediction!\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}